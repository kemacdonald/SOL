---
title: "SOL BDA Extra Simulations"
author: "Kyle MacDonald"
output: html_document
---

In this document, we present a brief analysis and visualization of the latent mixture component of our bayesian data analysis model. Specifically, we show posterior distributions over the indicator variable assigning each participant to the "guessing" or the "knowledge" group.

```{r, echo = F}
rm(list=ls()) # clear workspcace
knitr::opts_chunk$set(fig.height=4, fig.width=7, cache = T, warning=F, message=F, results = "hide")
```

```{r, echo = F}
library(langcog)
library(knitr)
library(R2jags)
library(dplyr)
library(ggplot2)
library(tidyr)
library(polspline)
library(magrittr)
library(stringr)
theme_set(theme_bw())
```

```{r}
window_simulations_fun <- function(list_of_dfs, predictor, outcome, model_type, prior_list) {
  df_final <- data.frame()
  counter <- 0
  
  # check what predictors are to get which variables to unstandardize
  if ( predictor == "age.s") {
    unstandardized_pred <- "age_peek_months"
  } else if ( predictor == "voc.s" ) {
    unstandardized_pred <- "signs_produced"
  } else if ( predictor == "acc.s") {
    unstandardized_pred <- "mean_prop_looking_TD" 
  } else {
    unstandardized_pred <- "median_rt"
  }
  
  if ( !(model_type %in% c("accuracy", "rt", "rt_no_mix")) ) {
    stop("Incorrect model type specification")
  }
  
  for (df in list_of_dfs) {
    for (prior in prior_list) {
      counter <- counter + 1
      window_name <- unique(df$window)
      prior_name <- prior
      model_path <- paste("models/", model_type, "_model.txt", sep = "")
      
      dataList <- list(
        y = unlist(df[outcome]),
        x = unlist(df[predictor]),
        Ntotal = length(unlist(df[predictor])),
        n_correct = unlist(df["C_T_count"]),
        n_trials = unlist(df["total_trials_shifting"]),
        prior = prior_name
      )
      
      ## Draw samples from the prior and posterior for given window and a given prior
      samples <- jags(data = dataList, parameters.to.save = parameters,
                      model.file = model_path, n.chains=nChains, 
                      n.iter=nIter, n.burnin = burnInSteps,
                      n.thin=thinSteps, DIC=F)
      
      ## Grab just the parameters we care about
      if ( model_type == "accuracy") {
        
        df_tmp <- data.frame(window = window_name,
                             slope_prior = prior_name,
                             zbeta0 = samples$BUGSoutput$sims.list$zbeta0, 
                             zbeta1 = samples$BUGSoutput$sims.list$zbeta1,
                             zbeta1_prior = samples$BUGSoutput$sims.list$zbeta1_prior,
                             zbeta0_prior = samples$BUGSoutput$sims.list$zbeta0_prior,
                             stringsAsFactors = F)
        
        ## Unstandardized variable
        unstandardized_outcome <- "mean_prop_looking_TD"
      } else if ( model_type == "rt" ) {
        
        df_tmp <- data.frame(window = window_name,
                             slope_prior = prior_name,
                             zbeta0 = samples$BUGSoutput$sims.list$true_beta0,
                             zbeta1 = samples$BUGSoutput$sims.list$true_beta1,
                             zbeta0_prior = samples$BUGSoutput$sims.list$true_beta0_prior,
                             zbeta1_prior = samples$BUGSoutput$sims.list$true_beta1_prior,
                             z = samples$BUGSoutput$sims.list$z,
                             stringsAsFactors = F)
        ## Unstandardized variable
        unstandardized_outcome <- "median_rt"
        
      } else if (model_type == "rt_no_mix") {
        
        df_tmp <- data.frame(window = window_name,
                             slope_prior = prior_name,
                             zbeta0 = samples$BUGSoutput$sims.list$zbeta0, 
                             zbeta1 = samples$BUGSoutput$sims.list$zbeta1,
                             zbeta1_prior = samples$BUGSoutput$sims.list$zbeta1_prior,
                             zbeta0_prior = samples$BUGSoutput$sims.list$zbeta0_prior,
                             stringsAsFactors = F)
        ## Unstandardized variable
        unstandardized_outcome <- "median_rt"
      }
      
      # standardize the data
      sd_unstand_out <- sd(unlist(df[unstandardized_outcome]))
      mean_unstand_out <- mean(unlist(df[unstandardized_outcome]))
      sd_unstand_pred <- sd(unlist(df[unstandardized_pred]))
      mean_unstand_pred <- mean(unlist(df[unstandardized_pred]))
      
      df_tmp %<>%  
        mutate(beta1 = zbeta1 * sd_unstand_out / sd_unstand_pred,
               beta1_prior = zbeta1_prior * sd_unstand_out / sd_unstand_pred,
               beta0 = zbeta0 * sd_unstand_out + mean_unstand_out - 
                 (zbeta1 * mean_unstand_pred * sd_unstand_out) / sd_unstand_pred,
               beta0_prior = zbeta0_prior * sd_unstand_out + mean_unstand_out - 
                 (zbeta1_prior * mean_unstand_pred * sd_unstand_out) / sd_unstand_pred,
               iteration = seq(1, nrow(.)))
      # store in final data frame
      df_final <- rbind(df_final, df_tmp)
    }
  }
  return(df_final)
} 


HDIofMCMC = function( sampleVec , credMass=0.95 ) {
    # Computes highest density interval from a sample of representative values,
    #   estimated as shortest credible interval.
    # Arguments:
    #   sampleVec
    #     is a vector of representative values from a probability distribution.
    #   credMass
    #     is a scalar between 0 and 1, indicating the mass within the credible
    #     interval that is to be estimated.
    # Value:
    #   HDIlim is a vector containing the limits of the HDI
    sortedPts = sort( sampleVec )
    ciIdxInc = ceiling( credMass * length( sortedPts ) )
    nCIs = length( sortedPts ) - ciIdxInc
    ciWidth = rep( 0 , nCIs )
    for ( i in 1:nCIs ) {
        ciWidth[ i ] = sortedPts[ i + ciIdxInc ] - sortedPts[ i ]
    }
    HDImin = sortedPts[ which.min( ciWidth ) ]
    HDImax = sortedPts[ which.min( ciWidth ) + ciIdxInc ]
    HDIlim = c( HDImin , HDImax )
    return( HDIlim )
}
```

Load data.

```{r}
d <- read.csv("../../data/processed_data/summary_tables/sol_ss_dage_models.csv", 
              stringsAsFactors = F)

d_voc <- read.csv("../../data/processed_data/summary_tables/sol_ss_dvoc_models.csv", 
                  stringsAsFactors = F)
```

Subset data by each analysis window.

```{r subset data by analysis window}
d_2200 <- filter(d, window == "600_2200")
d_2500 <- filter(d, window == "600_2500")
d_2800 <- filter(d, window == "600_2800")
d_voc_2200 <- filter(d_voc, window == "600_2200")
d_voc_2500 <- filter(d_voc, window == "600_2500")
d_voc_2800 <- filter(d_voc, window == "600_2800")
```

```{r}
# make list of  data frames to loop over
dfs <- list(d_2200, d_2500, d_2800)
dfs_voc <- list(d_voc_2200, d_voc_2500, d_voc_2800)
```


```{r}
adaptSteps = 500  # Number of steps to "tune" the samplers
nChains = 3 
thinSteps = 1
numSavedSteps = 21000
nIter = ceiling( ( numSavedSteps * thinSteps ) / nChains )
burnInSteps = nIter / 2
parameters = c( "zbeta0" , "zbeta1", "zbeta1_prior", "zbeta0_prior")
```

### RT and age no latent mixture

Draw samples from all three analysis windows.

```{r}
slope_priors <- c(.1, .5, 1, 2)
df_rt_age_final <- window_simulations_fun(list_of_dfs = dfs_voc, 
                                           predictor = "age.s", outcome = "rt.s", 
                                           model = "rt_no_mix",
                                          prior_list = slope_priors)


df_rt_voc_final <- window_simulations_fun(list_of_dfs = dfs_voc, 
                                           predictor = "voc.s", outcome = "rt.s", 
                                           model = "rt_no_mix",
                                          prior_list = slope_priors)
```

Inspect chains for convergence and see any differences across windows.

```{r}
a <- ggplot(aes(x=iteration, y=beta1), data = df_rt_age_final) + 
  geom_line() +
  ggtitle("Trace of Slope Parameter for Accuracy ~ Age") +
  facet_grid(slope_prior~window)  +
  scale_color_solarized() +
  xlab("Iteration Number") +
  guides(color = F)

b <- ggplot(aes(x=iteration, y=beta1), data = df_rt_voc_final) + 
  geom_line() +
  ggtitle("Trace of Slope Parameter for Accuracy ~ Vocab") +
  facet_grid(slope_prior~window)  +
  scale_color_solarized() +
  xlab("Iteration Number") +
  guides(color = F)

gridExtra::grid.arrange(a, b, ncol = 2)
```

Get means and 95% HDIs.

```{r}
df_rt_age_final %>% 
    group_by(window, slope_prior) %>% 
    summarise(mean = mean(beta1),
              lower = HDIofMCMC(beta1)[1],
              upper = HDIofMCMC(beta1)[2])

df_rt_voc_final %>% 
    group_by(window, slope_prior) %>% 
    summarise(mean = mean(beta1),
              lower = HDIofMCMC(beta1)[1],
              upper = HDIofMCMC(beta1)[2])
```


### Output of latent mixture models inferring guessing probability

```{r}
dataList_lat_mix = list(
    n_correct = d_2500$C_T_count,
    n_trials = d_2500$total_trials_shifting,
    Ntotal = length(d_2500$acc.s)
)

myinits <-  list(list(phi = 0.75, z = round(runif(length(d_2500$total_trials_shifting)))))

parameters <- c("z")

samples_post <- jags(data = dataList_lat_mix, parameters.to.save = parameters,
                model.file = "models/latent_mixture.txt", n.chains=1, inits = myinits,
                n.iter=nIter, n.burnin = burnInSteps,
                n.thin=1, DIC=T)

df_latent_mix <- data.frame(z = samples_post$BUGSoutput$sims.list$z)

# grab subject numbers and add to data frame
colnames(df_latent_mix)[which(names(df_latent_mix)=="z.1"):which(names(df_latent_mix)=="z.29")] <- as.character(d$Sub.Num)

# melt data frame
df_melt <- reshape::melt.data.frame(df_latent_mix[,2:length(df_latent_mix)], variable.name = "Sub.Num", value.name = "group_membership")

# change factor label
df_melt %<>% mutate(group_membership_factor = factor(df_melt$value, labels = c("G", "K")),
                    model = "latent_mix") 
```

```{r, fig.height=10, fig.width = }
## summarise
ms <- df_melt %>% 
    group_by(variable) %>% 
    summarise(prop_guessing = (length(value) - sum(value)) / length(value)) %>% 
    mutate(prop_guessing_convert = prop_guessing * .1)

ggplot(data=ms,aes(x=variable, y = prop_guessing)) +
    geom_bar(stat="identity") +
    guides(fill=F) +
    langcog::scale_fill_solarized() +
    ylim(0,1) +
    theme_bw()+
    xlab('Participant ID#') +
    ylab("Posterior Probability Guessing") +
    ggtitle("Results of Latent Mixture Model")
```
