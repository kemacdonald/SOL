---
title: "SOL BDA"
author: "Kyle MacDonald"
date: "June 19, 2015"
output: html_document
---

## SOL Experiment

* 29 kids complete ASL version of the LWL task (Fernald et al., 1998). Each kid is given 32 2-AFC trials. We want to analyze the relations between RT and age/productive ASL vocabulary. 

* But RTs are only meaningful if they are generated by the underlying process of interest: speed of lexcial access. Put another way, you can be fast (or slow) in the VLP task for the wrong reasons, because you are just guessing.

* So we want some way to flag participants that we think are likely to be guessing on our task. 

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width = 9, echo=T, warning=F, cache=F, message=F, sanitize = T)
```

```{r, echo=F}
library(langcog)
library(knitr)
library(R2jags)
library(gridExtra)
library(reshape2)
library(ggplot2)
library(dplyr)
library(magrittr)
library(MASS)
theme_set(theme_bw())
```

## Data structure

```{r, echo=F}
df_correct <- read.csv("../../paper/sol_ss_kids.csv")

df_correct %<>%  
    mutate(C_D_count = ifelse(is.na(C_D_count), 0, C_D_count),
        total_trials_shifting = C_T_count + C_D_count) %>% 
    dplyr::select(Sub.Num, age_cdi_months, signs_produced, C_T_count, total_trials_shifting, 
                  mean_correct_rt, C_T_prop)

kable(head(df_correct))
```

## Visualize 

```{r, echo = F}
ggplot(aes(x=age_cdi_months, y=mean_correct_rt), data = df_correct) +
    geom_point() +
    geom_smooth(method = "lm") + 
    ylim(800, 1750) +
    ggrepel::geom_text_repel(aes(label = C_T_prop), force = 10)
```

## Model (Lee and Wagenmakers, 2013)

```{r, echo = F}
grid::grid.raster(png::readPNG("latent-mixture-bda.png"))
```

* We assume there are two different groups of people with different probabilities of success, and we want to know something about the overall rate of success and the unobserved group memberships. 

* The probability of success on each question for each person is the rate θi. This rate is either ψ, if the person is in the guessing group, or φ if the person is in the knowledge group. 

* Which group each person belongs to is determined by a binary indicator variable zi (0: guessing; 1: knowledge)

* We assume each of these indicator variables is equally likely to be 0 or 1 a priori, so they have the prior zi ∼ Bernoulli(􏰀1/2).

* For the guessing group, we assume that the rate is ψ = 1/2. 

* For the knowledge group, we use a prior where all rate possibilities greater than 0.5 are equally likely, so that φ ∼ Uniform(􏰀0.5, 1􏰁.)


```{r,fig.width=12, fig.height=6, cache=F}
# Note: I adjusted the model to allow for different number of trials for each participants.
# change n to n[i] in the for loop.
cat('# Exam Scores
model{
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.5)
  }
  # First Group Guesses
  psi <- 0.5
  # Second Group Has Some Unknown Greater Rate Of Success
  phi ~ dbeta(1,1)I(0.5,1)
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi
    k[i] ~ dbin(theta[i],n[i])
  }
}', file={f<-tempfile()})
```

## Initial values 

1. Number of participants
2. Number correct for each participant
3. Number of trials for each participant

```{r}
p <- nrow(df_correct)                         # number of participants
k <- df_correct$C_T_count                     # number correct for each participant
n <- df_correct$total_trials_shifting         # number of trials for each participant

daa <- list("p", "k", "n")                             # data passed on to JAGS
myinits <-  list(list(phi = 0.75, z = round(runif(p)))) # Initial group assignment
```

## Parameters to be monitored

1. φ (the success rate of the knowledge group)
2. z (group membership: knowledge or guessing)

```{r}
parameters <- c("phi","z") 

# get samples
samples <- jags(data, inits=myinits, parameters,
                model.file=f, n.chains=1, n.iter=1000, 
                n.burnin=1, n.thin=1, DIC=T)

# extract values from model
df <- data.frame(phi = samples$BUGSoutput$sims.list$phi,
                 z = samples$BUGSoutput$sims.list$z)

kable(head(df))
```

Visualize parameter values

```{r, echo = F, fig.width=10}
# grab subject numbers
colnames(df)[which(names(df)=="z.1"):which(names(df)=="z.29")] <- as.character(df_correct$Sub.Num)

# melt data frame
df_melt <- melt(df[,2:length(df)], variable.name = "Sub.Num", value.name = "group_membership")

# change factor label
df_melt %<>% mutate(group_membership_factor = factor(df_melt$group_membership, 
                                                     labels = c("G", "K"))) 

a <- qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
    theme_bw()+
    xlab('phi')+
    xlim(0,1)

b <- ggplot(data=df_melt,aes(x=group_membership_factor, fill=group_membership_factor)) +
    geom_bar(stat="count") +
    facet_wrap(~Sub.Num,scales='fixed')+
    guides(fill=F) +
    scale_fill_solarized() +
    theme_bw()+
    xlab('Group Membership') +
    ylab("Count")

grid.arrange(a,b,nrow=1, top='Group success rate and individual group membership', 
             widths = c(2, 4))
```

## Flag guessers

Need some criterion for flagging participant as guessing. 

```{r, echo = F}
m1_guessers <- df_melt %>% 
    group_by(Sub.Num) %>% 
    summarise(knowledge_count = sum(group_membership)) %>% 
    filter(knowledge_count <= 250) %>% # determines the proportion of posterior == "guessing"
    mutate(
        Sub.Num = as.character(Sub.Num),
        guessing_count = 1000 - knowledge_count,
        posterior_mass = round((guessing_count / 1000), 2)
    ) 

m1_guessers <- df_correct %>% 
    mutate(Sub.Num = as.character(Sub.Num)) %>% 
    dplyr::select(C_T_prop, Sub.Num, total_trials_shifting) %>% 
    left_join(x = m1_guessers, by = "Sub.Num")

knitr::kable(dplyr::select(m1_guessers, Sub.Num, posterior_mass, C_T_prop,
                           total_trials_shifting))
```

## Compare to binomial test against chance 

```{r, echo = F}
binom_guessers <- df_correct %>% 
    group_by(Sub.Num, C_T_prop) %>% 
    summarise(binom_estimate = binom.test(C_T_count, total_trials_shifting, 
                                          alternative = "greater")$estimate,
              binom_p = binom.test(C_T_count, total_trials_shifting, 
                                   alternative = "greater")$p.value) %>% 
    filter(binom_p >= .10) %>% 
    dplyr::select(Sub.Num, binom_p, C_T_prop) %>% 
    arrange(binom_p) 

knitr::kable(binom_guessers)
```
