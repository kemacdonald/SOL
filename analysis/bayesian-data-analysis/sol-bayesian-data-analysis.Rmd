---
title: "SOL BDA"
author: "Kyle MacDonald"
date: "June 19, 2015"
output: html_document
---

## SOL Experiment

* 29 kids complete ASL version of the LWL task (Fernald et al., 1998). Each kid is given 32 2-AFC trials. We want to analyze the relations between RT and age/productive ASL vocabulary. 

* But RTs are only meaningful if they are generated by the underlying process of interest: speed of lexcial access. Put another way, you can be fast (or slow) in the VLP task for the wrong reasons, because you are just guessing.

* So we want some way to flag participants that we think are likely to be guessing on our task. 

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width = 9, echo=T, warning=F, 
                      cache=F, message=F, sanitize = T)

library(langcog)
library(knitr)
library(R2jags)
library(gridExtra)
library(reshape2)
library(ggplot2)
library(dplyr)
library(magrittr)
library(MASS)
theme_set(theme_bw())
```

## Data structure

```{r, echo=F}
df_correct <- read.csv("../../analysis/eye_movements/sol_ss_all.csv")

df_correct %<>%  
    filter(age_group_collapsed == "Kids", value_cat == "Target") %>% 
    mutate(C_D_count = ifelse(is.na(C_D_count), 0, C_D_count),
        total_trials_shifting = C_T_count + C_D_count,
        Sub.Num = as.character(Sub.Num)) %>% 
    dplyr::select(Sub.Num, age_peek_months, signs_produced, C_T_count,
                  total_trials_shifting, mean_correct_rt, median_ct_rt,
                  C_T_prop, prop_looking)
```

## Visualize correlations

```{r, echo = F}
ggplot(aes(x=signs_produced, y=median_ct_rt), data = df_correct) +
    geom_point() +
    geom_smooth(method = "lm") + 
    ggrepel::geom_text_repel(aes(label = C_T_prop), force = 10)
```

## Model (Lee and Wagenmakers, 2013)

```{r, echo = F}
grid::grid.raster(png::readPNG("latent-mixture-bda.png"))
```

* We assume there are two different groups of people with different probabilities of success, and we want to know something about the overall rate of success and the unobserved group memberships. 

* The probability of success on each question for each person is the rate θi. This rate is either ψ, if the person is in the guessing group, or φ if the person is in the knowledge group. 

* Which group each person belongs to is determined by a binary indicator variable zi (0: guessing; 1: knowledge)

* We assume each of these indicator variables is equally likely to be 0 or 1 a priori, so they have the prior zi ∼ Bernoulli(􏰀1/2).

* For the guessing group, we assume that the rate is ψ = 1/2. 

* For the knowledge group, we use a prior where all rate possibilities greater than 0.5 are equally likely, so that φ ∼ Uniform(􏰀0.5, 1􏰁.)


```{r, cache=F}
cat(
 'model{
  # Each Person Belongs To One Of Two Latent Groups
  for (i in 1:p){
    z[i] ~ dbern(0.75)
  }
  # First Group Guesses
  psi <- 0.5
  # Second Group Has Some Unknown Greater Rate Of Success
  phi ~ dunif(0.5,1)
  # Data Follow Binomial With Rate Given By Each Persons Group Assignment
  for (i in 1:p){
    theta[i] <- equals(z[i],0)*psi+equals(z[i],1)*phi
    k[i] ~ dbin(theta[i],n[i])
  }
}', file={f<-tempfile()})
```

## Initial values 

```{r}
p <- nrow(df_correct)                         # number of participants
k <- df_correct$C_T_count                     # number correct for each participant
n <- df_correct$total_trials_shifting         # number of trials for each participant
age <- df_correct$age_peek_months             # age in months
prop_looking <- df_correct$prop_looking       # correct looking
rt <- df_correct$mean_correct_rt

data <- list("p", "k", "n", "age", "prop_looking")             # data passed on to JAGS
myinits <-  list(list(phi = 0.75, z = round(runif(p))))        # Initial group assignment
```

## Parameters to be monitored

1. φ (the success rate of the knowledge group)
2. z (group membership: knowledge or guessing)

```{r}
parameters <- c("phi","z", "junk_intercept", "actual_intercept", "slope", "variance") 

# get samples
samples <- jags(data, inits=myinits, parameters,
                model.file=f, n.chains=1, n.iter=1000, 
                n.burnin=1, n.thin=1, DIC=T)
```

## Extract values from model

```{r}
df <- data.frame(phi = samples$BUGSoutput$sims.list$phi,
                 z = samples$BUGSoutput$sims.list$z)
```

## Visualize parameter values

```{r, echo = F, fig.width=10}
# grab subject numbers
colnames(df)[which(names(df)=="z.1"):which(names(df)=="z.29")] <- as.character(df_correct$Sub.Num)

# melt data frame
df_melt <- melt(df[,2:length(df)], variable.name = "Sub.Num", value.name = "group_membership")

# change factor label
df_melt %<>% mutate(group_membership_factor = factor(df_melt$group_membership, 
                                                     labels = c("G", "K"))) 

a <- qplot(data=melt(df$phi),x=value,geom='histogram',binwidth=0.008)+
    theme_bw()+
    xlab('phi')+
    xlim(0,1)

b <- ggplot(data=df_melt,aes(x=group_membership_factor, 
                             fill=group_membership_factor)) +
    geom_bar(stat="count") +
    facet_wrap(~Sub.Num,scales='fixed')+
    guides(fill=F) +
    scale_fill_solarized() +
    theme_bw()+
    xlab('Group Membership') +
    ylab("Count")

grid.arrange(a,b,nrow=1, top='Group success rate and individual group membership', 
             widths = c(2, 4))
```

## Merge output of latent mixture model with summary stats

```{r, echo = F}
m1_guessers <- df_melt %>% 
    group_by(Sub.Num) %>% 
    summarise(knowledge_count = sum(group_membership)) %>% 
    mutate(
        Sub.Num = as.character(Sub.Num),
        guessing_count = 1000 - knowledge_count,
        posterior_mass = round((guessing_count / 1000), 2)
    ) 

df_correct <- left_join(df_correct, m1_guessers, by = "Sub.Num")
```

## Compare to binomial test against chance 

```{r, echo = F}
binom_guessers <- df_correct %>% 
    group_by(Sub.Num, C_T_prop) %>% 
    summarise(binom_estimate = binom.test(C_T_count, total_trials_shifting, 
                                          alternative = "greater")$estimate,
              binom_p = binom.test(C_T_count, total_trials_shifting, 
                                   alternative = "greater")$p.value) %>% 
    filter(binom_p >= .10) %>% 
    dplyr::select(Sub.Num, binom_p, C_T_prop) %>% 
    arrange(binom_p) 

knitr::kable(binom_guessers)
```

## Bayesian linear regression

```{r}
myData <- df_correct %>% 
    filter(is.na(signs_produced) == F) %>% 
    dplyr::select(Sub.Num, age_peek_months, mean_correct_rt, signs_produced, 
                  prop_looking, guessing_count, posterior_mass)
    

xName = "age_peek_months" ; yName = "prop_looking" ; wName="guessing_count"
fileNameRoot = "sol-linear-regression-"
graphFileType = "eps" 
```

### Load model

```{r}
source(file = "sol-bda-linear-regression.R")
```

### Generate the MCMC chain:
```{r}
mcmcCoda = genMCMC( data=myData , xName=xName , yName=yName , wName = NULL, 
                    numSavedSteps=20000 , saveName=fileNameRoot )
```

### Display diagnostics of chain, for specified parameters:

```{r}
parameterNames = varnames(mcmcCoda) # get all parameter names
for ( parName in parameterNames ) {
  diagMCMC( codaObject=mcmcCoda , parName=parName , 
            saveName=fileNameRoot , saveType=graphFileType )
}
```

### Get summary statistics of chain

```{r}
df <- data.frame(phi = samples$BUGSoutput$sims.list$phi,
                 z = samples$BUGSoutput$sims.list$z)

```

```{r}
summaryInfo = smryMCMC( mcmcCoda , 
                        compValBeta1=0.0 , ropeBeta1=c(-0.5,0.5) ,
                        saveName=fileNameRoot )
show(summaryInfo)
# Display posterior information:
plotMCMC( mcmcCoda , data=myData , xName=xName , yName=yName , 
          compValBeta1=0.0 , ropeBeta1=c(-0.5,0.5) ,
          pairsPlot=TRUE , showCurve=FALSE ,
          saveName=fileNameRoot , saveType=graphFileType )

# better plot 



```
